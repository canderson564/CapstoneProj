{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canderson564/CapstoneProj/blob/main/CapstoneData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AVM_Direct file"
      ],
      "metadata": {
        "id": "17p-s6pTjW88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3ADwIIFdmEb",
        "outputId": "a5953287-4060-49cd-beee-c840d493af35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Fips  PropertyID                APN SitusFullStreetAddress  \\\n",
            "0       19153    54180959  010/00002-000-000       112 VIRGINIA AVE   \n",
            "1       19153    54180961  010/00003-000-000       120 VIRGINIA AVE   \n",
            "2       19153    54180963  010/00004-000-000       124 VIRGINIA AVE   \n",
            "3       19153    54181074  010/00013-000-000        615 BOULDER AVE   \n",
            "4       19153    54181075  010/00014-000-000        709 BOULDER AVE   \n",
            "...       ...         ...                ...                    ...   \n",
            "154784  19153    54369235  320/01252-108-005    1204 49TH ST UNIT 5   \n",
            "154785  19153    54369236  320/01252-108-006    1204 49TH ST UNIT 6   \n",
            "154786  19153    54369237  320/01252-108-007    1204 49TH ST UNIT 7   \n",
            "154787  19153    54369238  320/01252-108-008    1204 49TH ST UNIT 8   \n",
            "154788  19153    54369240  320/01252-117-000      4901 WOODLAND AVE   \n",
            "\n",
            "        SitusHouseNbr  SitusHouseNbrSuffix SitusDirectionLeft SitusStreet  \\\n",
            "0               112.0                  NaN                NaN    VIRGINIA   \n",
            "1               120.0                  NaN                NaN    VIRGINIA   \n",
            "2               124.0                  NaN                NaN    VIRGINIA   \n",
            "3               615.0                  NaN                NaN     BOULDER   \n",
            "4               709.0                  NaN                NaN     BOULDER   \n",
            "...               ...                  ...                ...         ...   \n",
            "154784         1204.0                  NaN                NaN        49TH   \n",
            "154785         1204.0                  NaN                NaN        49TH   \n",
            "154786         1204.0                  NaN                NaN        49TH   \n",
            "154787         1204.0                  NaN                NaN        49TH   \n",
            "154788         4901.0                  NaN                NaN    WOODLAND   \n",
            "\n",
            "       SitusMode SitusDirectionRight  ... SitusState SitusZIP5 SitusZIP4  \\\n",
            "0            AVE                 NaN  ...         IA   50315.0    7050.0   \n",
            "1            AVE                 NaN  ...         IA   50315.0    7050.0   \n",
            "2            AVE                 NaN  ...         IA   50315.0    7050.0   \n",
            "3            AVE                 NaN  ...         IA   50315.0    7036.0   \n",
            "4            AVE                 NaN  ...         IA   50315.0    2256.0   \n",
            "...          ...                 ...  ...        ...       ...       ...   \n",
            "154784        ST                 NaN  ...         IA   50266.0    5435.0   \n",
            "154785        ST                 NaN  ...         IA   50266.0    5435.0   \n",
            "154786        ST                 NaN  ...         IA   50266.0    5435.0   \n",
            "154787        ST                 NaN  ...         IA   50266.0    5435.0   \n",
            "154788       AVE                 NaN  ...         IA   50266.0    1739.0   \n",
            "\n",
            "       SitusCarrierCode  FinalValue  HighValue  LowValue  ConfidenceScore  \\\n",
            "0                  C094    151000.0   173000.0  132000.0               90   \n",
            "1                  C094    153000.0   173000.0  135000.0               63   \n",
            "2                  C094    145000.0   162000.0  130000.0               70   \n",
            "3                  C094    240000.0   279000.0  207000.0                1   \n",
            "4                  C094    167000.0   187000.0  149000.0               81   \n",
            "...                 ...         ...        ...       ...              ...   \n",
            "154784             C038    129000.0   144000.0  115000.0               81   \n",
            "154785             C038    130000.0   147000.0  114000.0               80   \n",
            "154786             C038    129000.0   144000.0  115000.0               81   \n",
            "154787             C038    129000.0   144000.0  115000.0               81   \n",
            "154788             C025    403000.0   473000.0  343000.0                1   \n",
            "\n",
            "        StandardDeviation  ValuationDate  \n",
            "0                      22       20231006  \n",
            "1                      17       20231006  \n",
            "2                      20       20231006  \n",
            "3                      10       20231006  \n",
            "4                      24       20231006  \n",
            "...                   ...            ...  \n",
            "154784                 10       20231006  \n",
            "154785                 19       20231006  \n",
            "154786                  9       20231006  \n",
            "154787                 10       20231006  \n",
            "154788                  6       20231006  \n",
            "\n",
            "[154789 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = 'AVM_Direct19153.txt'\n",
        "\n",
        "# Specify the delimiter used in your text file\n",
        "delimiter = '|'\n",
        "\n",
        "# Read the text file into a DataFrame\n",
        "dfAVM = pd.read_csv(file_path, delimiter=delimiter)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(dfAVM)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, median, mode\n",
        "from scipy import stats\n",
        "# mean(dfAVM['HighValue'])\n",
        "# median(dfAVM['HighValue'])\n",
        "# mode(dfAVM['HighValue'])\n",
        "# stats.iqr(dfAVM['FinalValue'])\n",
        "print(max(dfAVM['FinalValue']))\n",
        "print(median(dfAVM['HighValue']))\n",
        "dfAVM.hist('ConfidenceScore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "E58wEwaPszX7",
        "outputId": "c2b41ba7-4384-4bce-a8cc-a5063f2fc064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3063000.0\n",
            "274000.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<Axes: title={'center': 'ConfidenceScore'}>]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Equity file"
      ],
      "metadata": {
        "id": "J8apBWo3jriH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'Equity19153.txt'\n",
        "\n",
        "# Specify the delimiter used in your text file\n",
        "delimiter = '|'\n",
        "\n",
        "# Read the text file into a DataFrame\n",
        "dfEquity = pd.read_csv(file_path, delimiter=delimiter)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(dfEquity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AswPDNPLjbCi",
        "outputId": "8e2edd51-37a7-4e7c-875b-b08cbf5d3341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-f03f80af1fb1>:7: DtypeWarning: Columns (15,35,40,41,55,73,84,94,100) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dfEquity = pd.read_csv(file_path, delimiter=delimiter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Fips  PropertyID                APN  APNSeqNbr  OldAPN  \\\n",
            "0       19153    54180961  010/00003-000-000        NaN     NaN   \n",
            "1       19153    54180963  010/00004-000-000        NaN     NaN   \n",
            "2       19153    54181074  010/00013-000-000        NaN     NaN   \n",
            "3       19153    54181075  010/00014-000-000        NaN     NaN   \n",
            "4       19153    54181078  010/00016-000-000        NaN     NaN   \n",
            "...       ...         ...                ...        ...     ...   \n",
            "102705  19153    54372986  320/04928-272-000        NaN     NaN   \n",
            "102706  19153    54373016  320/04941-000-000        NaN     NaN   \n",
            "102707  19153    54373142  320/04947-031-312        NaN     NaN   \n",
            "102708  19153    54373164  320/04947-031-334        NaN     NaN   \n",
            "102709  19153    54373216  320/04947-031-414        NaN     NaN   \n",
            "\n",
            "        OldApnIndicator  TaxAccountNumber SitusFullStreetAddress  \\\n",
            "0                   NaN               NaN       120 VIRGINIA AVE   \n",
            "1                   NaN               NaN       124 VIRGINIA AVE   \n",
            "2                   NaN               NaN        615 BOULDER AVE   \n",
            "3                   NaN               NaN        709 BOULDER AVE   \n",
            "4                   NaN               NaN        801 BOULDER AVE   \n",
            "...                 ...               ...                    ...   \n",
            "102705              NaN               NaN            915 45TH ST   \n",
            "102706              NaN               NaN           1059 23RD ST   \n",
            "102707              NaN               NaN            184 57TH CT   \n",
            "102708              NaN               NaN    5949 COTTONWOOD CIR   \n",
            "102709              NaN               NaN      5870 BEECHTREE DR   \n",
            "\n",
            "        SitusHouseNbr  SitusHouseNbrSuffix  ... Mtg3EstLoanBalance  \\\n",
            "0               120.0                  NaN  ...                NaN   \n",
            "1               124.0                  NaN  ...                NaN   \n",
            "2               615.0                  NaN  ...                NaN   \n",
            "3               709.0                  NaN  ...                NaN   \n",
            "4               801.0                  NaN  ...                NaN   \n",
            "...               ...                  ...  ...                ...   \n",
            "102705          915.0                  NaN  ...                NaN   \n",
            "102706         1059.0                  NaN  ...                NaN   \n",
            "102707          184.0                  NaN  ...                NaN   \n",
            "102708         5949.0                  NaN  ...                NaN   \n",
            "102709         5870.0                  NaN  ...                NaN   \n",
            "\n",
            "       Mtg4EstLoanBalance Mtg1EstInterestRate Mtg2EstInterestRate  \\\n",
            "0                     NaN               360.0                 NaN   \n",
            "1                     NaN               411.0                 NaN   \n",
            "2                     NaN               485.0                 NaN   \n",
            "3                     NaN               310.0               633.0   \n",
            "4                     NaN               290.0                 NaN   \n",
            "...                   ...                 ...                 ...   \n",
            "102705                NaN               343.0                 NaN   \n",
            "102706                NaN               280.0                 NaN   \n",
            "102707                NaN               510.0                 NaN   \n",
            "102708                NaN               292.0                 NaN   \n",
            "102709                NaN               412.0               681.0   \n",
            "\n",
            "       Mtg3EstInterestRate Mtg4EstInterestRate   CLTV  CLBTV  FATimestamp  \\\n",
            "0                      NaN                 NaN  56.85  42.32     20230319   \n",
            "1                      NaN                 NaN  35.37  26.97     20230319   \n",
            "2                      NaN                 NaN  77.18  64.59     20230319   \n",
            "3                      NaN                 NaN  35.37  34.14     20230421   \n",
            "4                      NaN                 NaN  84.87  81.99     20230319   \n",
            "...                    ...                 ...    ...    ...          ...   \n",
            "102705                 NaN                 NaN  52.64  41.35     20230319   \n",
            "102706                 NaN                 NaN  31.17  29.75     20230319   \n",
            "102707                 NaN                 NaN  75.23  74.60     20230319   \n",
            "102708                 NaN                 NaN  52.39  28.76     20230319   \n",
            "102709                 NaN                 NaN  63.01  50.11     20230811   \n",
            "\n",
            "        FARecordType  \n",
            "0                  C  \n",
            "1                  C  \n",
            "2                  C  \n",
            "3                  C  \n",
            "4                  C  \n",
            "...              ...  \n",
            "102705             C  \n",
            "102706             C  \n",
            "102707             C  \n",
            "102708             C  \n",
            "102709             C  \n",
            "\n",
            "[102710 rows x 120 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HOALien File"
      ],
      "metadata": {
        "id": "9ltuV5WujwNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'HOALien19153.txt'\n",
        "\n",
        "# Specify the delimiter used in your text file\n",
        "delimiter = '|'\n",
        "\n",
        "# Read the text file into a DataFrame\n",
        "dfHOA = pd.read_csv(file_path, delimiter=delimiter)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(dfHOA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mwiG9H8jyqI",
        "outputId": "bed4ba2a-fa96-4763-b421-f8c6cee56ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        FIPS   PropertyID                APN  APNSeqNbr  OldAPN  \\\n",
            "0      19153          NaN                NaN        NaN     NaN   \n",
            "1      19153          NaN                NaN        NaN     NaN   \n",
            "2      19153          NaN                NaN        NaN     NaN   \n",
            "3      19153          NaN                NaN        NaN     NaN   \n",
            "4      19153          NaN                NaN        NaN     NaN   \n",
            "...      ...          ...                ...        ...     ...   \n",
            "15383  19153  172936632.0  261/00074-079-031        NaN     NaN   \n",
            "15384  19153  172936633.0  261/00074-079-032        NaN     NaN   \n",
            "15385  19153  172936633.0  261/00074-079-032        NaN     NaN   \n",
            "15386  19153  172941997.0  181/00014-071-021        NaN     NaN   \n",
            "15387  19153  172942000.0  181/00014-071-024        NaN     NaN   \n",
            "\n",
            "       OldApnIndicator  TaxAccountNumber SitusFullStreetAddress  \\\n",
            "0                  NaN               NaN                    NaN   \n",
            "1                  NaN               NaN                    NaN   \n",
            "2                  NaN               NaN                    NaN   \n",
            "3                  NaN               NaN                    NaN   \n",
            "4                  NaN               NaN                    NaN   \n",
            "...                ...               ...                    ...   \n",
            "15383              NaN               NaN   607 E VISTA LAKE AVE   \n",
            "15384              NaN               NaN   704 E VISTA LAKE AVE   \n",
            "15385              NaN               NaN   704 E VISTA LAKE AVE   \n",
            "15386              NaN               NaN     1203 NW JACKSON DR   \n",
            "15387              NaN               NaN     1109 NW JACKSON DR   \n",
            "\n",
            "       SitusHouseNbr  SitusHouseNbrSuffix  ... HOA Trustee/Attorney Name  \\\n",
            "0                NaN                  NaN  ...                       NaN   \n",
            "1                NaN                  NaN  ...                       NaN   \n",
            "2                NaN                  NaN  ...                       NaN   \n",
            "3                NaN                  NaN  ...                       NaN   \n",
            "4                NaN                  NaN  ...                       NaN   \n",
            "...              ...                  ...  ...                       ...   \n",
            "15383          607.0                  NaN  ...                       NaN   \n",
            "15384          704.0                  NaN  ...                       NaN   \n",
            "15385          704.0                  NaN  ...                       NaN   \n",
            "15386         1203.0                  NaN  ...                       NaN   \n",
            "15387         1109.0                  NaN  ...                       NaN   \n",
            "\n",
            "      HOA Trustee/Attorney Phone Number HOA Auction Date  \\\n",
            "0                                   NaN              NaN   \n",
            "1                                   NaN              NaN   \n",
            "2                                   NaN              NaN   \n",
            "3                                   NaN              NaN   \n",
            "4                                   NaN              NaN   \n",
            "...                                 ...              ...   \n",
            "15383                               NaN              NaN   \n",
            "15384                               NaN              NaN   \n",
            "15385                               NaN              NaN   \n",
            "15386                               NaN              NaN   \n",
            "15387                               NaN              NaN   \n",
            "\n",
            "      NOD_NOS - Orig Recording Date NOD_NOS - Orig Doc Number  \\\n",
            "0                               NaN                       NaN   \n",
            "1                               NaN                       NaN   \n",
            "2                               NaN                       NaN   \n",
            "3                               NaN                       NaN   \n",
            "4                               NaN                       NaN   \n",
            "...                             ...                       ...   \n",
            "15383                           NaN                       NaN   \n",
            "15384                           NaN                       NaN   \n",
            "15385                           NaN                       NaN   \n",
            "15386                           NaN                       NaN   \n",
            "15387                           NaN                       NaN   \n",
            "\n",
            "      NOD_NOS - Orig Book Number NOD_NOS - Orig Page Number  \\\n",
            "0                            NaN                        NaN   \n",
            "1                            NaN                        NaN   \n",
            "2                            NaN                        NaN   \n",
            "3                            NaN                        NaN   \n",
            "4                            NaN                        NaN   \n",
            "...                          ...                        ...   \n",
            "15383                        NaN                        NaN   \n",
            "15384                        NaN                        NaN   \n",
            "15385                        NaN                        NaN   \n",
            "15386                        NaN                        NaN   \n",
            "15387                        NaN                        NaN   \n",
            "\n",
            "      Open Lien Indicator  FA Timestamp  FAUCID Flag  \n",
            "0                       T      20220520            U  \n",
            "1                       F      20220520            U  \n",
            "2                       T      20220520            U  \n",
            "3                       T      20220520            U  \n",
            "4                       T      20220520            U  \n",
            "...                   ...           ...          ...  \n",
            "15383                   F      20230407            I  \n",
            "15384                   F      20230413            U  \n",
            "15385                   F      20230508            I  \n",
            "15386                   F      20230418            I  \n",
            "15387                   F      20230418            I  \n",
            "\n",
            "[15388 rows x 77 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ee5dd0541d38>:7: DtypeWarning: Columns (33,45,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dfHOA = pd.read_csv(file_path, delimiter=delimiter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INVL file"
      ],
      "metadata": {
        "id": "a6nPxum0kTuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'INVL19153.txt'\n",
        "\n",
        "# Specify the delimiter used in your text file\n",
        "delimiter = '|'\n",
        "\n",
        "# Read the text file into a DataFrame\n",
        "dfINVL = pd.read_csv(file_path, delimiter=delimiter)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(dfINVL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfzCl_X5kWk1",
        "outputId": "b8bc0820-aa81-49a1-fddd-a3b37ea83528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       TransactionID   Fips State       County  DocumentYear  Recordingdt  \\\n",
            "0         8035240924  19153    IA  Polk County          2022     20220523   \n",
            "1         8035265074  19153    IA  Polk County          2022     20220524   \n",
            "2         8035270296  19153    IA  Polk County          2022     20220524   \n",
            "3         8049941775  19153    IA  Polk County          2023     20230222   \n",
            "4         8035241773  19153    IA  Polk County          2022     20220523   \n",
            "...              ...    ...   ...          ...           ...          ...   \n",
            "35708     8052963186  19153    IA  Polk County          2023     20230420   \n",
            "35709     8054764605  19153    IA  Polk County          2023     20230629   \n",
            "35710     8055470308  19153    IA  Polk County          2023     20230726   \n",
            "35711     8054789431  19153    IA  Polk County          2023     20230630   \n",
            "35712     8053392957  19153    IA  Polk County          2023     20230508   \n",
            "\n",
            "       DocumentDt  doc_filing_date     DocNbrSrce BookSrce  ... StreetType  \\\n",
            "0             NaN              NaN   202200041558    19120  ...        NaN   \n",
            "1             NaN              NaN  2022-00042049    19122  ...        AVE   \n",
            "2             NaN              NaN  2022-00042066    19122  ...        NaN   \n",
            "3             NaN              NaN   202300007999    19400  ...         ST   \n",
            "4             NaN              NaN   202200041327    19119  ...         ST   \n",
            "...           ...              ...            ...      ...  ...        ...   \n",
            "35708         NaN              NaN   202300018670    19451  ...         ST   \n",
            "35709         NaN              NaN   202300033534    19522  ...        NaN   \n",
            "35710         NaN              NaN   202300039191    19549  ...        NaN   \n",
            "35711         NaN              NaN   202300033954    19524  ...        NaN   \n",
            "35712         NaN              NaN  2023-00022095    19467  ...        AVE   \n",
            "\n",
            "      SuiteType  Suite             City PropState      Zip   Plus4  \\\n",
            "0           NaN    NaN              NaN       NaN      NaN     NaN   \n",
            "1           NaN    NaN       DES MOINES        IA  50313.0  4205.0   \n",
            "2           NaN    NaN              NaN       NaN      NaN     NaN   \n",
            "3           NaN    NaN       DES MOINES        IA  50316.0  2413.0   \n",
            "4           NaN    NaN        URBANDALE        IA  50322.0  2414.0   \n",
            "...         ...    ...              ...       ...      ...     ...   \n",
            "35708       NaN    NaN       DES MOINES        IA  50315.0  1009.0   \n",
            "35709       NaN    NaN              NaN       NaN      NaN     NaN   \n",
            "35710       NaN    NaN              NaN       NaN      NaN     NaN   \n",
            "35711       NaN    NaN              NaN       NaN      NaN     NaN   \n",
            "35712       NaN    NaN  WINDSOR HEIGHTS        IA  50324.0  5847.0   \n",
            "\n",
            "       FaTimestamp  FARecordType     FAFormattedAPN  \n",
            "0         20220529             U  040/51712-005-000  \n",
            "1         20220529             U  070/02413-000-000  \n",
            "2         20221107             U                NaN  \n",
            "3         20230226             U  110/00209-000-000  \n",
            "4         20220529             U  312/02006-000-000  \n",
            "...            ...           ...                ...  \n",
            "35708     20230428             U  010/06467-000-000  \n",
            "35709     20230705             U  060/00713-129-000  \n",
            "35710     20230801             U                NaN  \n",
            "35711     20230706             U                NaN  \n",
            "35712     20230509             U  292/01536-000-000  \n",
            "\n",
            "[35713 rows x 162 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-4c80ebcf61a5>:7: DtypeWarning: Columns (10,24,50,67,68,82,100,102,104,105,118,120,122,123,132,134,135,137,139,142,143,149) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dfINVL = pd.read_csv(file_path, delimiter=delimiter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listing file"
      ],
      "metadata": {
        "id": "nOsbKsjYksu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'Listing19153.txt'\n",
        "\n",
        "# Specify the delimiter used in your text file\n",
        "delimiter = '|'\n",
        "\n",
        "# Read the text file into a DataFrame\n",
        "dfListing = pd.read_csv(file_path, delimiter=delimiter)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(dfListing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX1nhFqxkvHP",
        "outputId": "a7e328dc-0d4c-457a-bc1f-73232e55d5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          SitusFullStreetAddress SitusHouseNbr SitusDirectionLeft  \\\n",
            "0     14 Prairie Trail Plat 3 St            14                NaN   \n",
            "1     03 Prairie Trail Plat 3 St            03                NaN   \n",
            "2                506 16th Ave SE           506                NaN   \n",
            "3               7766 NE 27th Ave          7766                 NE   \n",
            "4                 9157 Calvin Dr          9157                NaN   \n",
            "...                          ...           ...                ...   \n",
            "2442           165 Burr Oak Blvd           165                NaN   \n",
            "2443               NW 77th Ln 10           NaN                 NW   \n",
            "2444     1645 SW Magazine Rd 203          1645                 SW   \n",
            "2445         4900 Pleasant St 14          4900                NaN   \n",
            "2446            3025 Holcomb Ave          3025                NaN   \n",
            "\n",
            "               SitusStreet SitusMode SitusDirectionRight SitusUnitNbr  \\\n",
            "0     Prairie Trail Plat 3        St                 NaN          NaN   \n",
            "1     Prairie Trail Plat 3        St                 NaN          NaN   \n",
            "2                     16th       Ave                  SE          NaN   \n",
            "3                     27th       Ave                 NaN          NaN   \n",
            "4                   Calvin        Dr                 NaN          NaN   \n",
            "...                    ...       ...                 ...          ...   \n",
            "2442              Burr Oak      Blvd                 NaN          NaN   \n",
            "2443                  77th        Ln                 NaN           10   \n",
            "2444              Magazine        Rd                 NaN          203   \n",
            "2445              Pleasant        St                 NaN           14   \n",
            "2446               Holcomb       Ave                 NaN          NaN   \n",
            "\n",
            "            SitusCity SitusState  SitusZIP5  ...                OfficeName  \\\n",
            "0              Ankeny         IA      50023  ...      New Home Site Realty   \n",
            "1              Ankeny         IA      50023  ...      New Home Site Realty   \n",
            "2             Altoona         IA      50009  ...           Re/Max Concepts   \n",
            "3             Altoona         IA      50009  ...       IOWA REALTY ALTOONA   \n",
            "4     West Des Moines         IA      50266  ...          Re/Max Precision   \n",
            "...               ...        ...        ...  ...                       ...   \n",
            "2442    Pleasant Hill         IA      50327  ...        Via Group Realtors   \n",
            "2443           Ankeny         IA      50023  ...  Exit Realty Capital City   \n",
            "2444           Ankeny         IA      50023  ...            Caliber Realty   \n",
            "2445  West Des Moines         IA      50266  ...    Iowa Realty Beaverdale   \n",
            "2446       Des Moines         IA      50310  ...    Iowa Realty Beaverdale   \n",
            "\n",
            "                                          OfficeAddress     OfficePhone  \\\n",
            "0       6900 Westown Pkwy West Des Moines IA 50266-2520             NaN   \n",
            "1       6900 Westown Pkwy West Des Moines IA 50266-2520             NaN   \n",
            "2                 550 36th Ave SW Altoona IA 50009-2626             NaN   \n",
            "3                   809 8th St SW Altoona IA 50009-2300             NaN   \n",
            "4                                                   NaN             NaN   \n",
            "...                                                 ...             ...   \n",
            "2442  1200 Valley West Dr West Des Moines IA 50266-1908             NaN   \n",
            "2443     200 Army Post Rd # 60 Des Moines IA 50315-6203  (515) 778-8628   \n",
            "2444                                                NaN  (515) 238-4528   \n",
            "2445           3521 Beaver Ave Des Moines IA 50310-3244             NaN   \n",
            "2446           3521 Beaver Ave Des Moines IA 50310-3244             NaN   \n",
            "\n",
            "      OfficeEmail ListingTrackingID        FAUniqueListingIdentifierRefID  \\\n",
            "0             NaN         142976332  202306072023090801429763320000000007   \n",
            "1             NaN         142977318  202306072023090801429773180000000006   \n",
            "2             NaN         139450909  202211052023090801394509090000000021   \n",
            "3             NaN         143562564  202307062023092401435625640000000015   \n",
            "4             NaN         143616151  202307082023092601436161510000000012   \n",
            "...           ...               ...                                   ...   \n",
            "2442          NaN         145260826  202309302023101101452608260000000005   \n",
            "2443          NaN         136648627  202206222023091601366486270000000021   \n",
            "2444          NaN         139719346  202211232023092401397193460000000027   \n",
            "2445          NaN         144832020  202309082023091801448320200000000004   \n",
            "2446          NaN         144791932  202309072023091701447919320000000004   \n",
            "\n",
            "      UpdateTimestamp  Add,Change,DeleteIndicator CurrentListingInd  \\\n",
            "0            20230908                           A                 Y   \n",
            "1            20230908                           A                 Y   \n",
            "2            20230908                           A                 Y   \n",
            "3            20230924                           A                 Y   \n",
            "4            20230926                           A                 Y   \n",
            "...               ...                         ...               ...   \n",
            "2442         20231011                           A                 Y   \n",
            "2443         20230916                           A                 Y   \n",
            "2444         20230924                           A               NaN   \n",
            "2445         20230918                           A                 Y   \n",
            "2446         20230917                           A                 Y   \n",
            "\n",
            "     CurrentRentalInd  \n",
            "0                 NaN  \n",
            "1                 NaN  \n",
            "2                 NaN  \n",
            "3                 NaN  \n",
            "4                 NaN  \n",
            "...               ...  \n",
            "2442              NaN  \n",
            "2443              NaN  \n",
            "2444              NaN  \n",
            "2445              NaN  \n",
            "2446              NaN  \n",
            "\n",
            "[2447 rows x 105 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOD File"
      ],
      "metadata": {
        "id": "_ErZ8EgVk_Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'NOD19153.txt'\n",
        "\n",
        "# Specify the delimiter used in your text file\n",
        "delimiter = '|'\n",
        "\n",
        "# Read the text file into a DataFrame\n",
        "dfNOD = pd.read_csv(file_path, delimiter=delimiter)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(dfNOD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1WNcPeQlA7b",
        "outputId": "1b203db4-5f76-4c32-b1a6-c167d2a972a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       FIPS  FATransactionID                APN  MultiAPN  \\\n",
            "0     19153       5066404803  060/01586-001-000       NaN   \n",
            "1     19153       5070383059  080/02462-000-000       NaN   \n",
            "2     19153       5067129232  060/01586-001-000       NaN   \n",
            "3     19153       5093445864  090/03287-000-000       NaN   \n",
            "4     19153       5098242871  270/01555-000-000       NaN   \n",
            "...     ...              ...                ...       ...   \n",
            "1583  19153       5111135769                NaN       NaN   \n",
            "1584  19153       5008459048  190/00730-001-000       NaN   \n",
            "1585  19153       5000024154  190/00730-001-000       NaN   \n",
            "1586  19153       5072289898  110/04534-000-000       NaN   \n",
            "1587  19153       5073356551  171/00725-000-000       NaN   \n",
            "\n",
            "     SitusFullStreetAddress  SitusHouseNbr  SitusHouseNbrSuffix  \\\n",
            "0            4127 E 28TH ST         4127.0                  NaN   \n",
            "1            2614 ADAMS AVE         2614.0                  NaN   \n",
            "2            4127 E 28TH ST         4127.0                  NaN   \n",
            "3              1146 35TH ST         1146.0                  NaN   \n",
            "4             70 NW 46TH PL           70.0                  NaN   \n",
            "...                     ...            ...                  ...   \n",
            "1583        2417 BOSTON AVE         2417.0                  NaN   \n",
            "1584       4531 NE 40TH AVE         4531.0                  NaN   \n",
            "1585       4531 NE 40TH AVE         4531.0                  NaN   \n",
            "1586        1557 ARTHUR AVE         1557.0                  NaN   \n",
            "1587         1915 6TH ST SW         1915.0                  NaN   \n",
            "\n",
            "     SitusDirectionLeft SitusStreet SitusMode  ... SubdivisionName Block  \\\n",
            "0                     E        28TH        ST  ...             NaN   NaN   \n",
            "1                   NaN       ADAMS       AVE  ...             NaN   NaN   \n",
            "2                     E        28TH        ST  ...             NaN   NaN   \n",
            "3                   NaN        35TH        ST  ...             NaN   NaN   \n",
            "4                    NW        46TH        PL  ...             NaN   NaN   \n",
            "...                 ...         ...       ...  ...             ...   ...   \n",
            "1583                NaN      BOSTON       AVE  ...             NaN   NaN   \n",
            "1584                 NE        40TH       AVE  ...             NaN   NaN   \n",
            "1585                 NE        40TH       AVE  ...             NaN   NaN   \n",
            "1586                NaN      ARTHUR       AVE  ...             NaN   NaN   \n",
            "1587                NaN         6TH        ST  ...             NaN   NaN   \n",
            "\n",
            "                          LegalDescription LotNumber  PropertyID  \\\n",
            "0      EX S 14F LT 183 DOUGLAS ACRES PLT 2       NaN  54260941.0   \n",
            "1                                      NaN       NaN  54195730.0   \n",
            "2      EX S 14F LT 183 DOUGLAS ACRES PLT 2       NaN  54260941.0   \n",
            "3                                      NaN       NaN  54199623.0   \n",
            "4     E 104 FT LOT 140 HIGHLAND PARK ACRES       NaN  54359995.0   \n",
            "...                                    ...       ...         ...   \n",
            "1583                                   NaN       NaN  54281304.0   \n",
            "1584   E 114 F LOT 73 CAPITOL HEIGHTS NO 2       NaN  54315400.0   \n",
            "1585   E 114 F LOT 73 CAPITOL HEIGHTS NO 2       NaN  54315400.0   \n",
            "1586                                   NaN       NaN  54247129.0   \n",
            "1587                                   NaN       NaN  54271914.0   \n",
            "\n",
            "      DeedFATransactionID  MortgageFATransactionID FATimeStamp  FARecordType  \\\n",
            "0                     NaN                      NaN    20230810             U   \n",
            "1                     NaN                      NaN    20230810             U   \n",
            "2                     NaN                      NaN    20230810             U   \n",
            "3                     NaN                      NaN    20230811             U   \n",
            "4                     NaN                      NaN    20230810             U   \n",
            "...                   ...                      ...         ...           ...   \n",
            "1583                  NaN                      NaN    20230811             U   \n",
            "1584                  NaN                      NaN    20230810             U   \n",
            "1585                  NaN                      NaN    20230810             U   \n",
            "1586                  NaN                      NaN    20230810             U   \n",
            "1587                  NaN                      NaN    20230810             U   \n",
            "\n",
            "      PFCType  \n",
            "0          NF  \n",
            "1          NF  \n",
            "2          NF  \n",
            "3          NF  \n",
            "4          NF  \n",
            "...       ...  \n",
            "1583       NF  \n",
            "1584       NF  \n",
            "1585       NF  \n",
            "1586       NF  \n",
            "1587       NF  \n",
            "\n",
            "[1588 rows x 88 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prop File"
      ],
      "metadata": {
        "id": "3tOD-LhslPUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'Prop19153.txt'\n",
        "\n",
        "# Specify the delimiter used in your text file\n",
        "delimiter = '|'\n",
        "\n",
        "# Read the text file into a DataFrame\n",
        "dfProp = pd.read_csv(file_path, delimiter=delimiter)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(dfProp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzkhqYMOlR5i",
        "outputId": "75d6c891-2f96-4bbb-d017-e8b5aacc650b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-5f8515d94276>:7: DtypeWarning: Columns (5,41,44,52,57,62,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dfProp = pd.read_csv(file_path, delimiter=delimiter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         FIPS  PropertyID                APN  APNSeqNbr  OldAPN  \\\n",
            "0       19153    54353531  241/01000-015-049        NaN     NaN   \n",
            "1       19153    54353717  241/01000-498-519        NaN     NaN   \n",
            "2       19153    54353724  241/01000-498-526        NaN     NaN   \n",
            "3       19153    54353731  241/01000-498-533        NaN     NaN   \n",
            "4       19153    54353910  241/01000-577-570        NaN     NaN   \n",
            "...       ...         ...                ...        ...     ...   \n",
            "215865  19153    54284246  190/00272-000-000        NaN     NaN   \n",
            "215866  19153    54234325  171/00460-484-035        NaN     NaN   \n",
            "215867  19153    54235948  180/00516-002-000        NaN     NaN   \n",
            "215868  19153    54322065  300/00079-000-000        NaN     NaN   \n",
            "215869  19153    54246227  140/00050-002-000        NaN     NaN   \n",
            "\n",
            "       OldApnIndicator  TaxAccountNumber   SitusFullStreetAddress  \\\n",
            "0                  NaN               NaN         5546 KIRKLAND CT   \n",
            "1                  NaN               NaN          5827 MARBLE CIR   \n",
            "2                  NaN               NaN           10029 AGATE LN   \n",
            "3                  NaN               NaN      5847 S GLENSTONE CT   \n",
            "4                  NaN               NaN            9556 ASTER LN   \n",
            "...                ...               ...                      ...   \n",
            "215865             NaN               NaN                      NaN   \n",
            "215866             NaN               NaN  1849 PARK MEADOWS DR SW   \n",
            "215867             NaN               NaN                      NaN   \n",
            "215868             NaN               NaN                      NaN   \n",
            "215869             NaN               NaN                      NaN   \n",
            "\n",
            "        SitusHouseNbr  SitusHouseNbrSuffix  ... Mtg3EstPaymentAmount  \\\n",
            "0              5546.0                  NaN  ...                  NaN   \n",
            "1              5827.0                  NaN  ...                  NaN   \n",
            "2             10029.0                  NaN  ...                  NaN   \n",
            "3              5847.0                  NaN  ...                  NaN   \n",
            "4              9556.0                  NaN  ...                  NaN   \n",
            "...               ...                  ...  ...                  ...   \n",
            "215865            NaN                  NaN  ...                  NaN   \n",
            "215866         1849.0                  NaN  ...                  NaN   \n",
            "215867            NaN                  NaN  ...                  NaN   \n",
            "215868            NaN                  NaN  ...                  NaN   \n",
            "215869            NaN                  NaN  ...                  NaN   \n",
            "\n",
            "       Mtg4EstPaymentAmount Mtg1EstLoanBalance Mtg2EstLoanBalance  \\\n",
            "0                       NaN           119371.0                NaN   \n",
            "1                       NaN           151937.0                NaN   \n",
            "2                       NaN           113856.0            24925.0   \n",
            "3                       NaN           125600.0                NaN   \n",
            "4                       NaN           297920.0                NaN   \n",
            "...                     ...                ...                ...   \n",
            "215865                  NaN                NaN                NaN   \n",
            "215866                  NaN                NaN                NaN   \n",
            "215867                  NaN                NaN                NaN   \n",
            "215868                  NaN                NaN                NaN   \n",
            "215869                  NaN                NaN                NaN   \n",
            "\n",
            "       Mtg3EstLoanBalance Mtg4EstLoanBalance Mtg1EstInterestRate  \\\n",
            "0                     NaN                NaN               437.0   \n",
            "1                     NaN                NaN               320.0   \n",
            "2                     NaN                NaN               365.0   \n",
            "3                     NaN                NaN               320.0   \n",
            "4                     NaN                NaN               527.0   \n",
            "...                   ...                ...                 ...   \n",
            "215865                NaN                NaN                 NaN   \n",
            "215866                NaN                NaN                 NaN   \n",
            "215867                NaN                NaN                 NaN   \n",
            "215868                NaN                NaN                 NaN   \n",
            "215869                NaN                NaN                 NaN   \n",
            "\n",
            "       Mtg2EstInterestRate  Mtg3EstInterestRate  Mtg4EstInterestRate  \n",
            "0                      NaN                  NaN                  NaN  \n",
            "1                      NaN                  NaN                  NaN  \n",
            "2                    470.0                  NaN                  NaN  \n",
            "3                      NaN                  NaN                  NaN  \n",
            "4                      NaN                  NaN                  NaN  \n",
            "...                    ...                  ...                  ...  \n",
            "215865                 NaN                  NaN                  NaN  \n",
            "215866                 NaN                  NaN                  NaN  \n",
            "215867                 NaN                  NaN                  NaN  \n",
            "215868                 NaN                  NaN                  NaN  \n",
            "215869                 NaN                  NaN                  NaN  \n",
            "\n",
            "[215870 rows x 84 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data shapes sizes and structure"
      ],
      "metadata": {
        "id": "8RquCrW3suxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AVMDataFrame:\", dfAVM.shape,dfAVM.size)\n",
        "print(\"EquityDataFrame:\",dfEquity.shape,dfEquity.size)\n",
        "print(\"HOADataFrame:\",dfHOA.shape,dfHOA.size)\n",
        "print(\"INVLDataFrame:\",dfINVL.shape,dfINVL.size)\n",
        "print(\"DataFrame:\",dfListing.shape,dfListing.size)\n",
        "print(\"NODDataFrame:\",dfNOD.shape,dfNOD.size)\n",
        "print(\"PropDataFrame:\",dfProp.shape,dfProp.size)\n",
        "print(\"Listing19143:\", dfListing.shape,dfListing.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHhmfFW7s3pl",
        "outputId": "3af636d6-aa35-4524-aa80-8a94ab452d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AVMDataFrame: (154789, 23) 3560147\n",
            "EquityDataFrame: (102710, 120) 12325200\n",
            "HOADataFrame: (15388, 77) 1184876\n",
            "INVLDataFrame: (35713, 162) 5785506\n",
            "DataFrame: (2447, 105) 256935\n",
            "NODDataFrame: (1588, 88) 139744\n",
            "PropDataFrame: (215870, 84) 18133080\n",
            "Listing19143: (2447, 105) 256935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in dfEquity.columns:\n",
        "    print(f\"{column}: {dfEquity[column].dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Nqidu5-VTO",
        "outputId": "2b39a575-6525-43bc-c1c5-71f3775c5bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fips: int64\n",
            "PropertyID: int64\n",
            "APN: object\n",
            "APNSeqNbr: float64\n",
            "OldAPN: float64\n",
            "OldApnIndicator: float64\n",
            "TaxAccountNumber: float64\n",
            "SitusFullStreetAddress: object\n",
            "SitusHouseNbr: float64\n",
            "SitusHouseNbrSuffix: float64\n",
            "SitusDirectionLeft: object\n",
            "SitusStreet: object\n",
            "SitusMode: object\n",
            "SitusDirectionRight: object\n",
            "SitusUnitType: object\n",
            "SitusUnitNbr: object\n",
            "SitusCity: object\n",
            "SitusState: object\n",
            "SitusZIP5: float64\n",
            "SitusZIP4: float64\n",
            "SitusCarrierCode: object\n",
            "SitusLatitude: float64\n",
            "SitusLongitude: float64\n",
            "SitusGeoStatusCode: object\n",
            "PropertyClassID: object\n",
            "LandUseCode: int64\n",
            "Owner1CorpInd: object\n",
            "Owner1LastName: object\n",
            "Owner1FirstName: object\n",
            "Owner1MiddleName: object\n",
            "Owner1Suffix: object\n",
            "Owner2CorpInd: object\n",
            "Owner2LastName: object\n",
            "Owner2FirstName: object\n",
            "Owner2MiddleName: object\n",
            "Owner2Suffix: object\n",
            "OwnerNAME1FULL: object\n",
            "OwnerNAME2FULL: object\n",
            "OwnerOccupied: object\n",
            "MailingFullStreetAddress: object\n",
            "MailingHouseNbr: object\n",
            "MailingHouseNbrSuffix: object\n",
            "MailingDirectionLeft: object\n",
            "MailingStreet: object\n",
            "MailingMode: object\n",
            "MailingDirectionRight: object\n",
            "MailingUnitType: object\n",
            "MailingUnitNbr: object\n",
            "MailingCity: object\n",
            "MailingState: object\n",
            "MailingZIP5: float64\n",
            "MailingZIP4: float64\n",
            "MailingCarrierCode: object\n",
            "MailingOptOut: object\n",
            "MailingCOName: object\n",
            "MailingForeignAddressInd: object\n",
            "TotalOpenLienNbr: int64\n",
            "TotalOpenLienAmt: int64\n",
            "Mtg1TransactionId: int64\n",
            "Mtg1RecordingDate: int64\n",
            "Mtg1LoanAmt: int64\n",
            "Mtg1Lender: object\n",
            "Mtg1PrivateLender: object\n",
            "Mtg1Term: int64\n",
            "Mtg1LoanDueDate: float64\n",
            "Mtg1AdjRider: object\n",
            "Mtg1LoanType: float64\n",
            "Mtg1TypeFinancing: object\n",
            "Mtg1LienPosition: int64\n",
            "Mtg2TransactionId: float64\n",
            "Mtg2RecordingDate: float64\n",
            "Mtg2LoanAmt: float64\n",
            "Mtg2Lender: object\n",
            "Mtg2PrivateLender: object\n",
            "Mtg2Term: float64\n",
            "Mtg2LoanDueDate: float64\n",
            "Mtg2AdjRider: object\n",
            "Mtg2LoanType: float64\n",
            "Mtg2TypeFinancing: object\n",
            "Mtg2LienPosition: float64\n",
            "Mtg3TransactionId: float64\n",
            "Mtg3RecordingDate: float64\n",
            "Mtg3LoanAmt: float64\n",
            "Mtg3Lender: object\n",
            "Mtg3PrivateLender: object\n",
            "Mtg3Term: float64\n",
            "Mtg3LoanDueDate: float64\n",
            "Mtg3AdjRider: float64\n",
            "Mtg3LoanType: float64\n",
            "Mtg3TypeFinancing: object\n",
            "Mtg3LienPosition: float64\n",
            "Mtg4TransactionId: float64\n",
            "Mtg4RecordingDate: float64\n",
            "Mtg4LoanAmt: float64\n",
            "Mtg4Lender: object\n",
            "Mtg4PrivateLender: float64\n",
            "Mtg4Term: float64\n",
            "Mtg4LoanDueDate: float64\n",
            "Mtg4AdjRider: float64\n",
            "Mtg4LoanType: float64\n",
            "Mtg4TypeFinancing: object\n",
            "Mtg4LienPosition: float64\n",
            "CurrentAVMValue: float64\n",
            "vLowValue: float64\n",
            "vHighValue: float64\n",
            "vConfidenceScore: float64\n",
            "vStandardDeviation: float64\n",
            "vValuationDate: int64\n",
            "Mtg1EstLoanBalance: float64\n",
            "Mtg2EstLoanBalance: float64\n",
            "Mtg3EstLoanBalance: float64\n",
            "Mtg4EstLoanBalance: float64\n",
            "Mtg1EstInterestRate: float64\n",
            "Mtg2EstInterestRate: float64\n",
            "Mtg3EstInterestRate: float64\n",
            "Mtg4EstInterestRate: float64\n",
            "CLTV: float64\n",
            "CLBTV: float64\n",
            "FATimestamp: int64\n",
            "FARecordType: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named dfEquity\n",
        "selected_columns = ['OwnerNAME1FULL', 'OwnerNAME2FULL', 'OwnerOccupied']\n",
        "\n",
        "# Extracting the specified columns\n",
        "selected_data = dfEquity[selected_columns]\n",
        "\n",
        "# Displaying the extracted data\n",
        "print(selected_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKcOm9HpYJiX",
        "outputId": "4bf0654b-b3b2-4934-bc62-a54e65415e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               OwnerNAME1FULL   OwnerNAME2FULL OwnerOccupied\n",
            "0             BICKEL JOSEPH C              NaN             Y\n",
            "1            DEFOREST ELLEN M              NaN             Y\n",
            "2               AMSDEN DANIEL   AMSDEN SHANNON             Y\n",
            "3            LARSON RANDALL C  GOMEZ SHANNON N             Y\n",
            "4       MILLER ANDREW DOUGLAS              NaN             Y\n",
            "...                       ...              ...           ...\n",
            "102705        JACOBSON RYAN T              NaN             Y\n",
            "102706       LADENBURGER JOHN              NaN             Y\n",
            "102707         KLEIN MICHELLE       KLEIN ADAM             Y\n",
            "102708     TRANNEL BENJAMIN J              NaN             Y\n",
            "102709           BERG BRYCE J              NaN             Y\n",
            "\n",
            "[102710 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'APN' is the common column in both dataframes\n",
        "merged_df = pd.merge(dfEquity, dfListing, on='APN', how='inner')\n",
        "\n",
        "# Count the number of matching items\n",
        "matching_count = len(merged_df)\n",
        "\n",
        "# Display the result\n",
        "print(f'The number of items from dfEquity that appear in dfListing is: {matching_count}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxaSdKJIcIqa",
        "outputId": "2680ee90-d00a-4842-a8e8-992e702e95a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of items from dfEquity that appear in dfListing is: 925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'SitusFullStreetAddress' is the common column in both dataframes\n",
        "Addressmerged_df = pd.merge(dfEquity, dfListing, on='SitusFullStreetAddress', how='inner')\n",
        "\n",
        "# Count the number of matching items\n",
        "matching_count = len(Addressmerged_df)\n",
        "\n",
        "# Display the result\n",
        "print(f'The number of items from dfEquity that appear in dfListing is: {matching_count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViXXdRkLsJOJ",
        "outputId": "ae731b95-60c6-475b-ed38-5f68506cd91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of items from dfEquity that appear in dfListing is: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'Mtg1LoanAmt' is the column in dfEquity\n",
        "loan_amount_range = dfEquity['Mtg1LoanAmt'].describe()[['min', 'max']]\n",
        "\n",
        "# Display the result\n",
        "print(f'The range of values in Mtg1LoanAmt is:\\n{loan_amount_range}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZS8TZvQrn_L",
        "outputId": "4ea49564-8ad4-4535-86d7-30e0df3e7859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The range of values in Mtg1LoanAmt is:\n",
            "min            1.0\n",
            "max    275110000.0\n",
            "Name: Mtg1LoanAmt, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "L4FoCPLBmcrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "initial predictive model"
      ],
      "metadata": {
        "id": "sM8HjOvOnY43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrames are named dfEquity and dfListing\n",
        "\n",
        "# Merge the two DataFrames based on the APN column\n",
        "merged_df = pd.merge(dfEquity, dfListing, on='APN', how='left')\n",
        "\n",
        "# Create a binary target variable indicating whether an APN appears in dfListing (1) or not (0)\n",
        "merged_df['AppearsInListing'] = merged_df['APN'].notnull().astype(int)\n",
        "\n",
        "# Select features (X) and target variable (y)\n",
        "features = ['Mtg1LoanAmt']  # Adding Mtg1LoanAmt as a feature\n",
        "X = merged_df[features]\n",
        "y = merged_df['AppearsInListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a RandomForestClassifier (you can choose a different model based on your needs)\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuUfuDLEp0lt",
        "outputId": "6dd71f7e-a45c-4cf9-fc20-0b66fcce212e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            "[[20548]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00     20548\n",
            "\n",
            "    accuracy                           1.00     20548\n",
            "   macro avg       1.00      1.00      1.00     20548\n",
            "weighted avg       1.00      1.00      1.00     20548\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Assuming your DataFrames are named dfEquity and dfListing\n",
        "\n",
        "# Merge the two DataFrames based on the APN column\n",
        "merged_df = pd.merge(dfEquity, dfListing, on='APN', how='left')\n",
        "\n",
        "# Create a binary target variable indicating whether an APN appears in dfListing (1) or not (0)\n",
        "merged_df['AppearsInListing'] = merged_df['APN'].notnull().astype(int)\n",
        "\n",
        "# Create categorical features based on Mtg1LoanAmt ranges\n",
        "merged_df['Mtg1LoanAmt_Range'] = pd.cut(\n",
        "    merged_df['Mtg1LoanAmt'],\n",
        "    bins=[-float('inf'), 40000, 60000, 80000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, float('inf')],\n",
        "    labels=['<40k', '40k-60k', '60k-80k','80k-100k','100k-150k','150k-200k',\n",
        "            '200k-250k','250k-300k','300k-350k','350k-400k','>400k'],\n",
        "    include_lowest=True\n",
        ")\n",
        "\n",
        "# Select features (X) and target variable (y)\n",
        "features = ['Mtg1LoanAmt_Range']  # Using the new categorical feature\n",
        "X = pd.get_dummies(merged_df[features])  # One-hot encode categorical feature\n",
        "y = merged_df['AppearsInListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a RandomForestClassifier (you can choose a different model based on your needs)\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfzeG6-Lr6rp",
        "outputId": "d168f776-b6e8-402a-988b-47fd8bc858d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            "[[20548]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00     20548\n",
            "\n",
            "    accuracy                           1.00     20548\n",
            "   macro avg       1.00      1.00      1.00     20548\n",
            "weighted avg       1.00      1.00      1.00     20548\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "likelihood of ending up in listing df based on  mortage loan 1 amount"
      ],
      "metadata": {
        "id": "fx6W1B5YvnmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Assuming your DataFrames are named dfEquity and dfListing\n",
        "\n",
        "# Merge the two DataFrames based on the APN column\n",
        "merged_df = pd.merge(dfEquity, dfListing, on='APN', how='left')\n",
        "\n",
        "# Create a binary target variable indicating whether an APN appears in dfListing (1) or not (0)\n",
        "merged_df['AppearsInListing'] = merged_df['APN'].notnull().astype(int)\n",
        "\n",
        "# Create categorical features based on Mtg1LoanAmt ranges\n",
        "merged_df['Mtg1LoanAmt_Range'] = pd.cut(\n",
        "    merged_df['Mtg1LoanAmt'],\n",
        "    bins=[-float('inf'), 40000, 60000, 80000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, float('inf')],\n",
        "    labels=['<40k', '40k-60k', '60k-80k', '80k-100k', '100k-150k', '150k-200k',\n",
        "            '200k-250k', '250k-300k', '300k-350k', '350k-400k', '>400k'],\n",
        "    include_lowest=True\n",
        ")\n",
        "\n",
        "# Calculate the percentage of APNs appearing in dfListing for each Mtg1LoanAmt_Range\n",
        "percentage_by_range = merged_df.groupby('Mtg1LoanAmt_Range')['AppearsInListing'].mean() * 100\n",
        "\n",
        "# Display the results\n",
        "print(\"Percentage of APNs from dfEquity appearing in dfListing by Mtg1LoanAmt_Range:\")\n",
        "print(percentage_by_range)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSE2rIHLvvoq",
        "outputId": "7d0ce987-0c49-49ce-cac4-6bb881132553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of APNs from dfEquity appearing in dfListing by Mtg1LoanAmt_Range:\n",
            "Mtg1LoanAmt_Range\n",
            "<40k         100.0\n",
            "40k-60k      100.0\n",
            "60k-80k      100.0\n",
            "80k-100k     100.0\n",
            "100k-150k    100.0\n",
            "150k-200k    100.0\n",
            "200k-250k    100.0\n",
            "250k-300k    100.0\n",
            "300k-350k    100.0\n",
            "350k-400k    100.0\n",
            ">400k        100.0\n",
            "Name: AppearsInListing, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrames are named dfEquity and dfListing\n",
        "\n",
        "# Create categorical features based on Mtg1LoanAmt ranges in dfEquity\n",
        "dfEquity['Mtg1LoanAmt_Range'] = pd.cut(\n",
        "    dfEquity['Mtg1LoanAmt'],\n",
        "    bins=[-float('inf'), 40000, 60000, 80000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, float('inf')],\n",
        "    labels=['<40k', '40k-60k', '60k-80k', '80k-100k', '100k-150k', '150k-200k',\n",
        "            '200k-250k', '250k-300k', '300k-350k', '350k-400k', '>400k'],\n",
        "    include_lowest=True\n",
        ")\n",
        "\n",
        "# Calculate the percentage of APNs in dfEquity that appear in dfListing for each Mtg1LoanAmt_Range\n",
        "percentage_by_range = dfEquity.groupby('Mtg1LoanAmt_Range').apply(lambda x: (x['APN'].isin(dfListing['APN']).sum() / len(x)) * 100)\n",
        "\n",
        "# Display the results\n",
        "print(\"Percentage of APNs from dfEquity appearing in dfListing by Mtg1LoanAmt_Range:\")\n",
        "print(percentage_by_range)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vANCZ0LJwb4L",
        "outputId": "a48f4aee-32ab-4059-dd1f-1eae0f796787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of APNs from dfEquity appearing in dfListing by Mtg1LoanAmt_Range:\n",
            "Mtg1LoanAmt_Range\n",
            "<40k         0.698964\n",
            "40k-60k      0.653290\n",
            "60k-80k      0.579151\n",
            "80k-100k     0.777443\n",
            "100k-150k    0.696689\n",
            "150k-200k    0.720115\n",
            "200k-250k    0.945890\n",
            "250k-300k    1.101423\n",
            "300k-350k    1.273345\n",
            "350k-400k    1.264852\n",
            ">400k        2.174411\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MabslcHNycSI",
        "outputId": "e55b8465-b2ec-4740-e20c-46cdcb49b64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         360.0\n",
            "1         411.0\n",
            "2         485.0\n",
            "3         310.0\n",
            "4         290.0\n",
            "          ...  \n",
            "102705    343.0\n",
            "102706    280.0\n",
            "102707    510.0\n",
            "102708    292.0\n",
            "102709    412.0\n",
            "Name: Mtg1EstInterestRate, Length: 102710, dtype: float64\n",
            "406.32442305631594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfEquityCopy = dfEquity.copy()"
      ],
      "metadata": {
        "id": "ppwhcJCo7Jar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming dfEquity and dfListing are your two dataframes\n",
        "# Merge the dataframes on the \"APN\" column\n",
        "merged_df = pd.merge(dfEquity, dfListing[['APN']], on='APN', how='left', indicator=True)\n",
        "\n",
        "# Create a new column based on the indicator column\n",
        "merged_df['In_dfListing'] = (merged_df['_merge'] == 'both').astype(int)\n",
        "\n",
        "# Drop the indicator column if you don't need it anymore\n",
        "merged_df = merged_df.drop('_merge', axis=1)\n",
        "\n",
        "# If you want to update dfEquity in-place, you can do the following\n",
        "dfEquity['In_dfListing'] = merged_df['In_dfListing']\n",
        "\n",
        "# If you want a new dataframe with the updated column, create a copy\n",
        "updated_dfEquity = dfEquity.copy()\n",
        "updated_dfEquity['In_dfListing'] = merged_df['In_dfListing']\n",
        "\n",
        "print(updated_dfEquity['In_dfListing'])\n",
        "print(updated_dfEquity['In_dfListing'].sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hXtKE5W7SQN",
        "outputId": "9a1c8af3-ca7f-45ab-acd8-e4fb305417bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         0\n",
            "1         0\n",
            "2         0\n",
            "3         0\n",
            "4         0\n",
            "         ..\n",
            "102705    0\n",
            "102706    0\n",
            "102707    0\n",
            "102708    0\n",
            "102709    0\n",
            "Name: In_dfListing, Length: 102710, dtype: int64\n",
            "925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' is the predictor column, and 'In_dfListing' is the target column\n",
        "\n",
        "# Filter the data based on the condition for 'Mtg1LoanAmt'\n",
        "filtered_data = updated_dfEquity[(updated_dfEquity['Mtg1LoanAmt'] >= 100000) & (updated_dfEquity['Mtg1LoanAmt'] <= 200000)]\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = filtered_data[['Mtg1LoanAmt']]\n",
        "y = filtered_data['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a logistic regression model\n",
        "logreg_model = LogisticRegression()\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe-_Rn2T9rWv",
        "outputId": "1649165d-8f7c-4829-e4ad-1f2fd155e76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.99\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      9103\n",
            "           1       0.00      0.00      0.00        76\n",
            "\n",
            "    accuracy                           0.99      9179\n",
            "   macro avg       0.50      0.50      0.50      9179\n",
            "weighted avg       0.98      0.99      0.99      9179\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Get the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate the misclassification rate\n",
        "misclassification_rate = (conf_matrix[0, 1] + conf_matrix[1, 0]) / conf_matrix.sum()\n",
        "\n",
        "# Print the misclassification rate\n",
        "print(f\"Misclassification Rate: {misclassification_rate:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmOKeJ_wHDkE",
        "outputId": "8c236a93-e574-494a-e861-15ea69850252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misclassification Rate: 0.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = dfEquity.isnull().sum()\n",
        "\n",
        "# Sort columns based on missing values count in descending order\n",
        "sorted_missing_values = missing_values.sort_values(ascending=False)\n",
        "\n",
        "# Select the top 10 columns\n",
        "top_10_missing = sorted_missing_values.head(20)\n",
        "\n",
        "# Display the result\n",
        "print(\"Top 20 columns with missing values:\")\n",
        "print(top_10_missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDCYaIz52Hkw",
        "outputId": "fdd2324e-998c-486c-b8ba-86de7dc79c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 columns with missing values:\n",
            "SitusHouseNbrSuffix         102710\n",
            "OldApnIndicator             102710\n",
            "Mtg4AdjRider                102710\n",
            "TaxAccountNumber            102710\n",
            "Mtg4PrivateLender           102710\n",
            "OldAPN                      102710\n",
            "Mtg3AdjRider                102710\n",
            "APNSeqNbr                   102709\n",
            "Mtg4TypeFinancing           102709\n",
            "Mtg3PrivateLender           102709\n",
            "MailingForeignAddressInd    102709\n",
            "MailingHouseNbrSuffix       102707\n",
            "Mtg2PrivateLender           102688\n",
            "Mtg4LoanDueDate             102681\n",
            "Mtg4EstInterestRate         102659\n",
            "Mtg4LoanAmt                 102659\n",
            "Mtg4TransactionId           102659\n",
            "Mtg4RecordingDate           102659\n",
            "Mtg4Term                    102659\n",
            "Mtg4Lender                  102659\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression model v1.2"
      ],
      "metadata": {
        "id": "P-AqSpcIUcHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Filter the data based on the condition for 'Mtg1LoanAmt'\n",
        "filtered_data = updated_dfEquity[(updated_dfEquity['Mtg1LoanAmt'] >= 100000) & (updated_dfEquity['Mtg1LoanAmt'] <= 200000)]\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = filtered_data[['Mtg1LoanAmt', 'Mtg1EstLoanBalance']]\n",
        "y = filtered_data['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Drop rows with NaN values from the predictor variables and update the target variable accordingly\n",
        "X_train.dropna(inplace=True)\n",
        "y_train = y_train[X_train.index]  # Update y_train accordingly\n",
        "\n",
        "# Drop rows with NaN values from the test predictor variables and update the target variable accordingly\n",
        "X_test.dropna(inplace=True)\n",
        "y_test = y_test[X_test.index]  # Update y_test accordingly\n",
        "\n",
        "# Create a logistic regression model\n",
        "logreg_model = LogisticRegression()\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijQY6PaUWrYq",
        "outputId": "36ad1386-266d-4565-8cb0-64a347b6035c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.99\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      9076\n",
            "           1       0.00      0.00      0.00        76\n",
            "\n",
            "    accuracy                           0.99      9152\n",
            "   macro avg       0.50      0.50      0.50      9152\n",
            "weighted avg       0.98      0.99      0.99      9152\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression v1.3"
      ],
      "metadata": {
        "id": "biooreQTW2yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Filter the data based on the condition for 'Mtg1LoanAmt'\n",
        "filtered_data = updated_dfEquity[(updated_dfEquity['Mtg1LoanAmt'] >= 100000) & (updated_dfEquity['Mtg1LoanAmt'] <= 200000)]\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = filtered_data[['Mtg1LoanAmt', 'Mtg1EstLoanBalance','Mtg1Term','Mtg1EstInterestRate']]\n",
        "y = filtered_data['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Drop rows with NaN values from the predictor variables and update the target variable accordingly\n",
        "X_train.dropna(inplace=True)\n",
        "y_train = y_train[X_train.index]  # Update y_train accordingly\n",
        "\n",
        "# Drop rows with NaN values from the test predictor variables and update the target variable accordingly\n",
        "X_test.dropna(inplace=True)\n",
        "y_test = y_test[X_test.index]  # Update y_test accordingly\n",
        "\n",
        "# Create a logistic regression model\n",
        "logreg_model = LogisticRegression()\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhQqiBs9W7Fv",
        "outputId": "e72562d6-7042-42a1-f425-cd901077e6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.99\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      9076\n",
            "           1       0.00      0.00      0.00        76\n",
            "\n",
            "    accuracy                           0.99      9152\n",
            "   macro avg       0.50      0.50      0.50      9152\n",
            "weighted avg       0.98      0.99      0.99      9152\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression model v1.4"
      ],
      "metadata": {
        "id": "2R2_3dhycE5A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kmc6WUycIRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Filter the data based on the condition for 'Mtg1LoanAmt'\n",
        "filtered_data = updated_dfEquity[(updated_dfEquity['Mtg1LoanAmt'] >= 100000) & (updated_dfEquity['Mtg1LoanAmt'] <= 200000)]\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = filtered_data[['Mtg1LoanAmt', 'Mtg1EstLoanBalance','Mtg1Term','Mtg1EstInterestRate','CurrentAVMValue','TotalOpenLienAmt']]\n",
        "y = filtered_data['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Drop rows with NaN values from the predictor variables and update the target variable accordingly\n",
        "X_train.dropna(inplace=True)\n",
        "y_train = y_train[X_train.index]  # Update y_train accordingly\n",
        "\n",
        "# Drop rows with NaN values from the test predictor variables and update the target variable accordingly\n",
        "X_test.dropna(inplace=True)\n",
        "y_test = y_test[X_test.index]  # Update y_test accordingly\n",
        "\n",
        "# Create a logistic regression model\n",
        "logreg_model = LogisticRegression()\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5ffb42-f573-484e-eca1-ebe99e383e5a",
        "id": "eKyskLJKcIx6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.99\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      9076\n",
            "           1       0.00      0.00      0.00        76\n",
            "\n",
            "    accuracy                           0.99      9152\n",
            "   macro avg       0.50      0.50      0.50      9152\n",
            "weighted avg       0.98      0.99      0.99      9152\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "random forest model v1.0"
      ],
      "metadata": {
        "id": "uWsXYEKqbLJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Filter the data based on the condition for 'Mtg1LoanAmt'\n",
        "filtered_data = updated_dfEquity[(updated_dfEquity['Mtg1LoanAmt'] >= 100000) & (updated_dfEquity['Mtg1LoanAmt'] <= 200000)]\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = filtered_data[['Mtg1LoanAmt', 'Mtg1EstLoanBalance','Mtg1Term','Mtg1EstInterestRate']]\n",
        "y = filtered_data['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Drop rows with NaN values from the predictor variables and update the target variable accordingly\n",
        "X_train.dropna(inplace=True)\n",
        "y_train = y_train[X_train.index]  # Update y_train accordingly\n",
        "\n",
        "# Drop rows with NaN values from the test predictor variables and update the target variable accordingly\n",
        "X_test.dropna(inplace=True)\n",
        "y_test = y_test[X_test.index]  # Update y_test accordingly\n",
        "\n",
        "# Create a random forest classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust n_estimators as needed\n",
        "\n",
        "# Train the model on the training set\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uR3aQXfbKd7",
        "outputId": "7f90dc0f-172e-4beb-a1bf-5e8ec4e86808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.99\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      9076\n",
            "           1       0.00      0.00      0.00        76\n",
            "\n",
            "    accuracy                           0.99      9152\n",
            "   macro avg       0.50      0.50      0.50      9152\n",
            "weighted avg       0.98      0.99      0.99      9152\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "random forest v1.1 w/ class balancing"
      ],
      "metadata": {
        "id": "rAeSurb3cmzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Filter the data based on the condition for 'Mtg1LoanAmt'\n",
        "filtered_data = updated_dfEquity[(updated_dfEquity['Mtg1LoanAmt'] >= 100000) & (updated_dfEquity['Mtg1LoanAmt'] <= 200000)]\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = filtered_data[['Mtg1LoanAmt', 'Mtg1EstLoanBalance', 'Mtg1Term', 'Mtg1EstInterestRate']]\n",
        "y = filtered_data['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Drop rows with NaN values from the predictor variables and update the target variable accordingly\n",
        "X_train.dropna(inplace=True)\n",
        "y_train = y_train[X_train.index]  # Update y_train accordingly\n",
        "\n",
        "# Drop rows with NaN values from the test predictor variables and update the target variable accordingly\n",
        "X_test.dropna(inplace=True)\n",
        "y_test = y_test[X_test.index]  # Update y_test accordingly\n",
        "\n",
        "# Create a random forest classifier model with class weights\n",
        "# 'balanced' automatically adjusts weights inversely proportional to class frequencies\n",
        "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
        "\n",
        "# Train the model on the training set\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model using F1-score\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX7ojfiZhrlI",
        "outputId": "ea1b6346-c985-404a-95e9-8def60c4a687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      9076\n",
            "           1       0.00      0.00      0.00        76\n",
            "\n",
            "    accuracy                           0.99      9152\n",
            "   macro avg       0.50      0.50      0.50      9152\n",
            "weighted avg       0.98      0.99      0.99      9152\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install imbalanced-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX3kjVELjufJ",
        "outputId": "715fd591-9eb7-46b0-964e-a9862ceec7e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "random forest model v1.2 w/ over sampling"
      ],
      "metadata": {
        "id": "uEM8sTzLgWZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Filter the data based on the condition for 'Mtg1LoanAmt'\n",
        "filtered_data = updated_dfEquity[(updated_dfEquity['Mtg1LoanAmt'] >= 100000) & (updated_dfEquity['Mtg1LoanAmt'] <= 200000)]\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = filtered_data[['Mtg1LoanAmt', 'Mtg1EstLoanBalance', 'Mtg1Term', 'Mtg1EstInterestRate']]\n",
        "y = filtered_data['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Drop rows with NaN values from the predictor variables and update the target variable accordingly\n",
        "X_train.dropna(inplace=True)\n",
        "y_train = y_train[X_train.index]  # Update y_train accordingly\n",
        "\n",
        "# Drop rows with NaN values from the test predictor variables and update the target variable accordingly\n",
        "X_test.dropna(inplace=True)\n",
        "y_test = y_test[X_test.index]  # Update y_test accordingly\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create a random forest classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the resampled training set\n",
        "rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywvUaMUij3FW",
        "outputId": "dab667c0-8ee5-4837-f4c2-3d79eceffc62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97      9076\n",
            "           1       0.01      0.05      0.02        76\n",
            "\n",
            "    accuracy                           0.95      9152\n",
            "   macro avg       0.50      0.50      0.50      9152\n",
            "weighted avg       0.98      0.95      0.97      9152\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Model v1.3  w/ Undersampling"
      ],
      "metadata": {
        "id": "8UyP6bxOxN17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Filter the data based on the condition for 'Mtg1LoanAmt'\n",
        "filtered_data = updated_dfEquity[(updated_dfEquity['Mtg1LoanAmt'] >= 100000) & (updated_dfEquity['Mtg1LoanAmt'] <= 200000)]\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = filtered_data[['Mtg1LoanAmt', 'Mtg1EstLoanBalance', 'Mtg1Term', 'Mtg1EstInterestRate']]\n",
        "y = filtered_data['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Drop rows with NaN values from the predictor variables and update the target variable accordingly\n",
        "X_train.dropna(inplace=True)\n",
        "y_train = y_train[X_train.index]  # Update y_train accordingly\n",
        "\n",
        "# Drop rows with NaN values from the test predictor variables and update the target variable accordingly\n",
        "X_test.dropna(inplace=True)\n",
        "y_test = y_test[X_test.index]  # Update y_test accordingly\n",
        "\n",
        "# Apply undersampling to the majority class\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Create a random forest classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the resampled training set\n",
        "rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqphPowhxU7A",
        "outputId": "46711919-64e4-457e-bb26-6c9a08e89fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.49      0.66      9076\n",
            "           1       0.01      0.59      0.02        76\n",
            "\n",
            "    accuracy                           0.49      9152\n",
            "   macro avg       0.50      0.54      0.34      9152\n",
            "weighted avg       0.98      0.49      0.65      9152\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest modeling v1.4 w/ hyperparameter sampling"
      ],
      "metadata": {
        "id": "0Ll_bP8ByjgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Filter the data based on the condition for 'Mtg1LoanAmt'\n",
        "filtered_data = updated_dfEquity[(updated_dfEquity['Mtg1LoanAmt'] >= 100000) & (updated_dfEquity['Mtg1LoanAmt'] <= 200000)]\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = filtered_data[['Mtg1LoanAmt', 'Mtg1EstLoanBalance', 'Mtg1Term', 'Mtg1EstInterestRate']]\n",
        "y = filtered_data['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Drop rows with NaN values from the predictor variables and update the target variable accordingly\n",
        "X_train.dropna(inplace=True)\n",
        "y_train = y_train[X_train.index]  # Update y_train accordingly\n",
        "\n",
        "# Drop rows with NaN values from the test predictor variables and update the target variable accordingly\n",
        "X_test.dropna(inplace=True)\n",
        "y_test = y_test[X_test.index]  # Update y_test accordingly\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='precision', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Get the best parameters and the best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Precision Score:\", best_score)\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "O06sNi1IyrNn",
        "outputId": "41d9d820-e82c-4626-fc5c-2a5fcf3a6231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-dd42ff6ff3e7>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Fit the GridSearchCV object to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Get the best parameters and the best score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "non filtered data frame testing"
      ],
      "metadata": {
        "id": "KaajJQ0cvs6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' is the predictor column, and 'In_dfListing' is the target column\n",
        "\n",
        "# Create the predictor (X) and target (y) variables using the entire dataset\n",
        "X = updated_dfEquity[['Mtg1LoanAmt']]\n",
        "y = updated_dfEquity['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a logistic regression model\n",
        "logreg_model = LogisticRegression()\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUxiyZKuvxFH",
        "outputId": "40b18a0b-3e78-4c4e-b5f0-8299fdf813fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.99\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00     20372\n",
            "           1       0.00      0.00      0.00       170\n",
            "\n",
            "    accuracy                           0.99     20542\n",
            "   macro avg       0.50      0.50      0.50     20542\n",
            "weighted avg       0.98      0.99      0.99     20542\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "unfiltered Random Forest Model v1.3 w/ Undersampling"
      ],
      "metadata": {
        "id": "Vv_tdi9cwpT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = updated_dfEquity[['Mtg1LoanAmt', 'Mtg1EstLoanBalance', 'Mtg1Term', 'Mtg1EstInterestRate']]\n",
        "y = updated_dfEquity['In_dfListing']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Drop rows with NaN values from the predictor variables and update the target variable accordingly\n",
        "X_train.dropna(inplace=True)\n",
        "y_train = y_train[X_train.index]  # Update y_train accordingly\n",
        "\n",
        "# Drop rows with NaN values from the test predictor variables and update the target variable accordingly\n",
        "X_test.dropna(inplace=True)\n",
        "y_test = y_test[X_test.index]  # Update y_test accordingly\n",
        "\n",
        "# Apply undersampling to the majority class\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Create a random forest classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the resampled training set\n",
        "rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaJROHIhw2LM",
        "outputId": "f3124706-fd88-45b1-a367-43d83fdb4091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.51      0.68     20319\n",
            "           1       0.01      0.48      0.02       170\n",
            "\n",
            "    accuracy                           0.51     20489\n",
            "   macro avg       0.50      0.49      0.35     20489\n",
            "weighted avg       0.98      0.51      0.67     20489\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking to see how many instances are present"
      ],
      "metadata": {
        "id": "vP4Ms_Nb1zKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of 1's in the 'In_dfListing' column\n",
        "num_ones = updated_dfEquity['In_dfListing'].value_counts()[0]\n",
        "\n",
        "print(f\"The number of 1's in the 'In_dfListing' column: {num_ones}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fmZDiP409ER",
        "outputId": "e710da79-2784-4217-81d6-bfc8277c486c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of 1's in the 'In_dfListing' column: 101785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing updated random forest model with undersampling and oversampling implemnted before splitting to train w/ missing values being replaced with the mean"
      ],
      "metadata": {
        "id": "_HfK6FMb2M1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = updated_dfEquity[['Mtg1LoanAmt', 'Mtg1EstLoanBalance', 'Mtg1Term', 'Mtg1EstInterestRate']]\n",
        "y = updated_dfEquity['In_dfListing']\n",
        "\n",
        "# Impute missing values in predictor variables\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "#print(\"Original data dimensions:\")\n",
        "#print(\"X shape:\", X.shape)\n",
        "#print(\"y shape:\", y.shape)\n",
        "\n",
        "# Apply undersampling to the majority class and oversampling to the minority class\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X_imputed, y)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_resampled, y_resampled)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a random forest classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the resampled training set\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUlRK-A32c_h",
        "outputId": "d05476bb-5107-4e4c-8ed1-6da80d018606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.45      0.46       190\n",
            "           1       0.44      0.46      0.45       180\n",
            "\n",
            "    accuracy                           0.46       370\n",
            "   macro avg       0.46      0.46      0.46       370\n",
            "weighted avg       0.46      0.46      0.46       370\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing updated random forest model with undersampling  implemnted before splitting to train w/ missing values being replaced with the mean"
      ],
      "metadata": {
        "id": "eIFNyfiwB08R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = updated_dfEquity[['Mtg1LoanAmt', 'Mtg1EstLoanBalance', 'Mtg1Term', 'Mtg1EstInterestRate']]\n",
        "y = updated_dfEquity['In_dfListing']\n",
        "\n",
        "# Impute missing values in predictor variables\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Apply undersampling to the majority class\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X_imputed, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a random forest classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the resampled training set\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIZyJqm9B64j",
        "outputId": "d638b503-f795-4291-e7d8-6ba845e4d3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.45      0.46       190\n",
            "           1       0.44      0.46      0.45       180\n",
            "\n",
            "    accuracy                           0.46       370\n",
            "   macro avg       0.46      0.46      0.46       370\n",
            "weighted avg       0.46      0.46      0.46       370\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "random undersampling with ratio testing"
      ],
      "metadata": {
        "id": "alHY8ew7FOHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = updated_dfEquity[['Mtg1LoanAmt', 'Mtg1EstLoanBalance', 'Mtg1Term', 'Mtg1EstInterestRate']]\n",
        "y = updated_dfEquity['In_dfListing']\n",
        "\n",
        "# Impute missing values in predictor variables\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Apply random undersampling with a specified ratio\n",
        "undersampler = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X_imputed, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a random forest classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the resampled training set\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report (Random Undersampling with Ratio):\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibs6F7HuFQzI",
        "outputId": "f894810d-68a1-4e77-bab4-5028af434ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Random Undersampling with Ratio):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.81      0.74       370\n",
            "           1       0.37      0.23      0.29       185\n",
            "\n",
            "    accuracy                           0.61       555\n",
            "   macro avg       0.53      0.52      0.51       555\n",
            "weighted avg       0.58      0.61      0.59       555\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing updated random forest model with undersampling and oversampling implemnted before splitting to train w/ missing values being dropped\n",
        "**DO NOT RUN**"
      ],
      "metadata": {
        "id": "HHqJ1Jqm4tWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "random undersampling with oversampling and gradient boosting"
      ],
      "metadata": {
        "id": "ii5aIdK95pGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Gradient Boosting classifier model\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Perform Grid Search for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "grid_search = GridSearchCV(gb_model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from Grid Search\n",
        "best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report (Gradient Boosting with SMOTE):\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SHOWD_95v-S",
        "outputId": "d86faa49-46a3-4690-91d4-92942d3df5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Gradient Boosting with SMOTE):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98     20417\n",
            "           1       0.99      0.98      0.98     20297\n",
            "\n",
            "    accuracy                           0.98     40714\n",
            "   macro avg       0.98      0.98      0.98     40714\n",
            "weighted avg       0.98      0.98      0.98     40714\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#DO NOT RUN!!!!!!!!!!!DO NOT RUN!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Remove rows with missing values\n",
        "drop_updated_dfEquity = updated_dfEquity.dropna(inplace=True)\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = drop_updated_dfEquity[['Mtg1LoanAmt', 'Mtg1EstLoanBalance', 'Mtg1Term', 'Mtg1EstInterestRate']]\n",
        "y = drop_updated_dfEquity['In_dfListing']\n",
        "\n",
        "# Apply undersampling to the majority class and oversampling to the minority class\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_resampled, y_resampled)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a random forest classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the resampled training set\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "OagX0tk541r-",
        "outputId": "246a8e22-e847-4026-8bf5-dfe4bf03382b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-b15f6994b687>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Create the predictor (X) and target (y) variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_updated_dfEquity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Mtg1LoanAmt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mtg1EstLoanBalance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mtg1Term'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mtg1EstInterestRate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_updated_dfEquity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'In_dfListing'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing updated random forest model with undersampling and oversampling implemnted before splitting to train w/ missing values being replaced with 0 **Do not run**"
      ],
      "metadata": {
        "id": "Ct2p2lru7YFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#DO not run!!!!!1 DO NOT RUN\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'updated_dfEquity' is your DataFrame\n",
        "# and 'Mtg1LoanAmt' and 'Mtg1EstLoanBalance' are the predictor columns,\n",
        "# and 'In_dfListing' is the target column\n",
        "\n",
        "# Fill missing values with 0\n",
        "updated_dfEquity.fillna(0, inplace=True)\n",
        "\n",
        "# Create the predictor (X) and target (y) variables\n",
        "X = updated_dfEquity[['Mtg1LoanAmt', 'Mtg1EstLoanBalance', 'Mtg1Term', 'Mtg1EstInterestRate']]\n",
        "y = updated_dfEquity['In_dfListing']\n",
        "\n",
        "# Apply undersampling to the majority class and oversampling to the minority class\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "smote = SMOTE(random_state=42)\n",
        "print(\"Original data dimensions:\")\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_resampled, y_resampled)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a random forest classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the resampled training set\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "d1JAcqRS7cs7",
        "outputId": "689c7ef2-f67a-4e87-ee87-87b3d6048653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data dimensions:\n",
            "X shape: (0, 4)\n",
            "y shape: (0,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by RandomUnderSampler.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-de921505c9d7>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mundersampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by RandomUnderSampler."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version 2.0 per presentation, with finding how deep the tree goes"
      ],
      "metadata": {
        "id": "W3sRA_9u3Usq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3P0SKIHe3bvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Gradient Boosting classifier model\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Perform Grid Search for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "grid_search = GridSearchCV(gb_model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from Grid Search\n",
        "best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report (Gradient Boosting with SMOTE):\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c272458f-489f-44ec-b4d9-1fcf721ab936",
        "id": "iziqDV1u3cPr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Gradient Boosting with SMOTE):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98     20417\n",
            "           1       0.99      0.98      0.98     20297\n",
            "\n",
            "    accuracy                           0.98     40714\n",
            "   macro avg       0.98      0.98      0.98     40714\n",
            "weighted avg       0.98      0.98      0.98     40714\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best max_depth\n",
        "best_max_depth = grid_search.best_params_['max_depth']\n",
        "print(\"\\nBest max_depth:\", best_max_depth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkPa-T5VS9JL",
        "outputId": "d4ecbcbf-0921-44d1-ecf5-573f9f01204d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best max_depth: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version 2.1 with dpeth of *5*"
      ],
      "metadata": {
        "id": "s-AyfFbLTRkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Gradient Boosting classifier model\n",
        "gb_model = GradientBoostingClassifier(max_depth=5, random_state=42)\n",
        "\n",
        "# Perform Grid Search for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    # 'max_depth': [3, 5, 7]  # Remove max_depth from param_grid\n",
        "}\n",
        "grid_search = GridSearchCV(gb_model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from Grid Search\n",
        "best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report (Gradient Boosting with SMOTE):\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbhLfpWzTPQR",
        "outputId": "4493030f-995c-461a-a4fb-20ff0759fbe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Gradient Boosting with SMOTE):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97     20417\n",
            "           1       0.97      0.97      0.97     20297\n",
            "\n",
            "    accuracy                           0.97     40714\n",
            "   macro avg       0.97      0.97      0.97     40714\n",
            "weighted avg       0.97      0.97      0.97     40714\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version 2.2 with depth of 3 and ratio set to 5:1"
      ],
      "metadata": {
        "id": "YG_FzZpoeN_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Apply SMOTE to oversample the minority class with a ratio of 5:1\n",
        "smote = SMOTE(sampling_strategy=0.2, random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Gradient Boosting classifier model with max_depth=3\n",
        "gb_model = GradientBoostingClassifier(max_depth=3, random_state=42)\n",
        "\n",
        "# Perform Grid Search for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "}\n",
        "grid_search = GridSearchCV(gb_model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from Grid Search\n",
        "best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report (Gradient Boosting with SMOTE and max_depth=3):\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0LfIEyKeRoi",
        "outputId": "9724f173-882e-4a5c-9963-5331b9415dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Gradient Boosting with SMOTE and max_depth=3):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97     20466\n",
            "           1       0.95      0.69      0.80      3963\n",
            "\n",
            "    accuracy                           0.94     24429\n",
            "   macro avg       0.94      0.84      0.88     24429\n",
            "weighted avg       0.94      0.94      0.94     24429\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version 2.3 with depth of 5 and ratio of 7:1"
      ],
      "metadata": {
        "id": "tee-1e22mflp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JPj4Du_myP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Apply SMOTE to oversample the minority class with a ratio of 7:1\n",
        "desired_ratio = 7\n",
        "smote = SMOTE(sampling_strategy={1: int(len(X_imputed) / (desired_ratio + 1))}, random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Gradient Boosting classifier model with max_depth=5\n",
        "gb_model = GradientBoostingClassifier(max_depth=5, random_state=42)\n",
        "\n",
        "# Perform Grid Search for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "}\n",
        "grid_search = GridSearchCV(gb_model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from Grid Search\n",
        "best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report (Gradient Boosting with SMOTE and max_depth=5):\")\n",
        "print(classification_rep)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d9d1cd-ecd7-44c2-ffcd-aec3af9d69c2",
        "id": "L77omkPUmzHa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Gradient Boosting with SMOTE and max_depth=5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     20501\n",
            "           1       0.92      0.76      0.83      2424\n",
            "\n",
            "    accuracy                           0.97     22925\n",
            "   macro avg       0.94      0.88      0.91     22925\n",
            "weighted avg       0.97      0.97      0.97     22925\n",
            "\n"
          ]
        }
      ]
    }
  ]
}